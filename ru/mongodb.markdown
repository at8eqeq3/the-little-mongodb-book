\thispagestyle{empty}
\changepage{}{}{}{-1.5cm}{}{2cm}{}{}{}
![The Little MongoDB Book, By Karl Seguin](ru/title.png)\ 

\clearpage
\changepage{}{}{}{1.5cm}{}{-2cm}{}{}{}

## Об этой книге ##

### Лицензия ###
«Маленькая книга про MongoDB» распространяется под лицензией Attribution-NonCommercial 3.0 Unported license. **Вы не должны платить за эту книгу.**

Вы можете свободно копировать, распространять, изменять и публиковать эту книгу. Однако, я прошу всегда указывать автора (Karl Seguin) и не использовать ее в коммерческих целях.

Полный текст лицензии можно найти здесь:

<http://creativecommons.org/licenses/by-nc/3.0/legalcode>

### Об авторе ###
Карл Сегуин - разработчик, имеющий опыт работы в различных областях и технологиях. Он - профессиональный разработчик на .NET и Ruby. Он - участник нескольких открытых проектов, технический писатель и участник конференций. Касательно MongoDB, он принимает участие в разработке NoRM - библиотеки на C#, создал интерактивный курс [mongly](http://mongly.com), а также [Mongo Web Admin](https://github.com/karlseguin/Mongo-Web-Admin). Его бесплатный сервис для разработчиков казуальных игр [mogade.com](http://mogade.com/) также работает на MongoDB.

Карл также написал [The Little Redis Book](http://openmymind.net/2012/1/23/The-Little-Redis-Book/) ([перевод](https://github.com/kondratovich/the-little-redis-book/) этой книги на русский выполнил [Андрей Кондратович](http://twitter.com/_sparrow)).

Его блог можно найти по адресу <http://openmymind.net>, его твиттер - [@karlseguin](http://twitter.com/karlseguin)

### Благодарности ###
Я особо благодарен [Perry Neal](http://twitter.com/perryneal) за то, что он позволил мне воспользоваться его глазами, разумом и увлеченностью. Твоя помощь неоценима. Спасибо тебе.

### Актуальная версия ###
Актуальная версия исходного кода книги доступна по адресу: 

<http://github.com/karlseguin/the-little-mongodb-book>.

### О переводе ###

Перевод подготовил [Дмитрий Григорьев](http://twitter.com/at8eqeq3). Актуальную версию исходников перевода можно получить по адресу <http://github.com/at8eqeq3/the-little-mongodb-book>.

\clearpage

## Введение ##
 > Я не виноват, что главы получились такими короткими. Это все от того, что MongoDB очень легко изучать.

Часто говорят, что технология развивается немыслимыми темпами. Да, список новых технологий и техник непрерывно растет. Однако, мне всегда казалось, что фундаментальные технологии, используемые программистами, движутся значительно медленнее. Можно потратить годы на изучение того, что еще осталось актуальным. Удивляет то с какой скоростью привычные технологии заменяются новыми. Нечто, казавшееся таким привычным, внезапно оказывается под угрозой быть забытым совсем.

Самым, пожалуй, примечательным образцом таких изменений может служить рост популярности NoSQL-технологий по сравнению с реляционными базами данных. Кажется, что еще вчера весь интернет держался на нескольких СУРБД, а сегодня уже пять, или около того, NoSQL-решений показывают себя весьма полезными.

И хотя кажется, что такие вещи происходят мгновенно, в реальности могут пройти годы, пока эти технологии станут широко распространены. Начальный энтузиазм подогревается относительно небольшими группами разработчиков и компаний. Оттачиваются решения, усваиваются уроки, и вот, видя, что технологии становятся более зрелыми, все остальные постепенно начинают пробовать их самостоятельно. Частично это так применительно к NoSQL-решениям, которые не способны полностью заменить традиционные хранилища, но предназначены для решения определенного круга задач в дополнении к ним.

Кроме сказанного выше, мы должны объяснить, что мы имеем в виду, говоря «NoSQL». Это очень неконкретное название, и для разных людей оно может означать разные вещи. Лично я часто использую его, чтобы назвать некую систему, играющую роль в хранении данных. С другой стороны, NoSQL (опять же, для меня) - это вера в то, что хранение данных не обязательно происходит в одной-единственной системе. Разработчики реляционных баз данных исторически пытаются представить свои продукты универсальными, NoSQL склоняется к небольшим зонам ответственности, где для каждой задачи может быть найден лучший инструмент. Таким образом, ваш NoSQL-стек может по-прежнему использовать реляционную базу (допустим, MySQL), но также иметь Redis в качестве persistence lookup(???) определенных частей системы, и еще Hadoop для обработки больших объемов данных. Проще говоря, NoSQL - это быть открытым и знать об альтернативах, существующих и новых способах и инструментах для управления данными.

Вы, наверное, задумались, как MongoDB относится к этому всему. Являясь документ-ориентированной базой данных, Mongo - это более общее NoSQL-решение. Её можно рассматривать как альтернативу реляционным базам. И, как реляционные базы, она тоже может выиграть, будучи связанной с другими, более специализированными NoSQL-решениями. MongoDB имеет свои достоинства и недостатки, о которых мы расскажем чуть дальше в этой книге.

Как вы уже, возможно, заметили, слова «MongoDB» и «Mongo» означают одно и то же.

## Начало работы ##
Большая часть этой книги описывает основной функционал MongoDB. Поэтому мы будем работать с оболочкой MongoDB. Оболочка полезна для обучения, и, ко всему прочему, является неплохим инструментом для управления, однако при написании кода вы будете использовать MongoDB-драйверы.

Вот и первое, что мы узнаем о MongoDB - её драйверы. У MongoDB есть [множество официальных драйверов](http://www.mongodb.org/display/DOCS/Drivers) для различных языков. Эти драйверы не сильно отличаются от возможно известных вам драйверов для других БД. На основе этих драйверов сообществом разработаны более специфичные для некоторых языков и фреймворков библиотеки. Например, [NoRM](https://github.com/atheken/NoRM) - библиотека для C#, использующая LINQ, и [MongoMapper](https://github.com/jnunemaker/mongomapper) - библиотека на Ruby, совместимая с ActiveRecord. Выбрать для работы низкоуровневый драйвер или более высокоуровневую библиотеку - дело исключительно ваше. Я говорю об этом лишь из-за того, что некоторые люди при знакомстве с MongoDB не понимают, почему есть официальные драйверы и библиотеки, разработанные сообществом; первые предназначены для низкоуровневого «общения» с БД, вторые - более «заточенные» под конкретный язык или фреймворк.

Я настоятельно советую при чтении этой книги воспроизводить мои действия самостоятельно, а также исследовать возможности для решения собственных вопросов. MongoDB достаточно просто установить, так что давайте потратим пару минут на подготовку всего необходимого.

1. Обратитесь к [официальной странице загрузок](http://www.mongodb.org/downloads) и скачайте бинарный дистрибутив из первой строчки (рекомендованную стабильную версию) для своей операционной системы. Для нужд разработки пойдет и 32-битная, и 64-битная.

2. Распакуйте архив (куда вам удобно) и перейдите в каталог `bin`. Пока не нужно ничего запускать, но запомните, что  `mongod` - это серверный процесс, а `mongo` - это клиентская оболочка. С этими двумя программами мы и будем проводить большую часть нашего времени.

3. Создайте в `bin` текстовый файл с названием `mongodb.config`.

4. Добавьте в него всего одну строчку: `dbpath=PATH_TO_WHERE_YOU_WANT_TO_STORE_YOUR_DATABASE_FILES`. Например, под Windows это может быть `dbpath=c:\mongodb\data`, а под Linux - `dbpath=/etc/mongodb/data`.

5. Убедитесь, что указанный в `dbpath` путь существует.

6. Запустите mongod с параметром `--config /path/to/your/mongodb.config`

Например, для пользователя Windows, если он распаковал архив в `c:\mongodb\` и создал `c:\mongodb\data\`, то в `c:\mongodb\bin\mongodb.config` ему нужно указать `dbpath=c:\mongodb\data\`, а запускать `mongod` из командной строки, выполнив `c:\mongodb\bin\mongod --config c:\mongodb\bin\mongodb.config`.

Чтобы сэкономить буквы, можно добавить каталог `bin` в переменную окружения `PATH`. Действия для пользователей Linux и MacOS примерно такие же. Отличаться будут только пути.

Надеюсь, что все прошло успешно и MongoDB работает. Если же вы получаете ошибку, то прочтите внимательно вывод: сервер обычно очень хорошо объясняет, что с ним не так.

Теперь вы можете запустить `mongo` (без *d*), который запустит оболочку к вашему серверу. Попробуйте ввести `db.version()`, чтобы убедиться, что все работает как надо. В идеале, вы должны увидеть номер установленной вами версии.

\clearpage

## Глава 1 - Основы ##
Мы начнём наше путешествие с исследования основных действий при работе с MongoDB. Очевидно, это есть ключ к пониманию сути MongoDB, но это также поможет найти ответы на более высокоуровневые вопросы применения MongoDB.

Для начала, вот вам 6 простых концепций, которые нужно понять:

1. MongoDB вкладывает в понятие «база данных» уже привычное вам значение (оракловоды называют это «схема»). В каждом экземпляре MongoDB может быть 0 или более баз данных, каждая из которых является контейнером для всего остального.

2. База данных может содержать 0 или более «коллекций». Коллекции во многом похожи на таблицы, и представлять их именно такими не будет ошибкой.

3. Коллекции состоят из 0 или более «документов». Документ, как уже можно догадаться, очень похож на строку.

4. Документ состоит и 1 или более «полей», которые, внезапно, можно сравнить со столбцами.

5. «Индексы» в MongoDB работают примерно так же, как и их тезки в СУРБД.

6. «Курсоры» отличаются от первых пяти концепций, но они не менее важны, хотя про них и часто забывают. Я думаю, они заслуживают отдельного упоминания. Самый важный момент касательно курсоров - это то, что когда вы запрашиваете данные у MongoDB, она возвращает курсор, с которым мы и работаем - считаем количество документов, листаем вперед-назад, а не сами данные.

Еще раз, MongoDB сделана из **баз данных**, которые содержат **коллекции**. **Коллекция** состоит из **документов**. Каждый **документ** имеет **поля**. **Коллекции** могут быть **проиндексированы** для повышения производительности поиска и сортировки. И, наконец, когда мы запрашиваем данные у MongoDB, мы делаем это через **курсор**, а реальное выполнение запросов откладывается, пока данные не станут необходимы.

Вам, вероятно, интересно, зачем использовать новую терминологию (коллекции вместо таблиц, документы вместо строк, поля вместо столбцов). Чтобы всё усложнить? На самом деле, соль в том, что хотя эти понятия и похожи на своих реляционных «коллег», они не идентичны. Основное различие в том, что реляционные базы определяют **столбцы** на уровне **таблиц**, тогда как документ-ориентированная база определяет **поля** на уровне **документов**. Таким образом, каждый **документ** в **коллекции** может иметь свой собственный уникальный набор **полей**. По сути, **коллекция** - это всего лишь контейнер по сравнению с **таблицей**, а **документ** хранит намного больше информации, чем **строка**.

Хотя это и очень важно понимать, не переживайте, если пока еще не все абсолютно ясно. После пары insert-ов будет понятнее. По большому счёту, суть в том, что коллекции не принципиально, что происходит внутри неё (она бессхемна). Поля принадлежат каждому отдельному документу. Достоинства и недостатки такого подхода мы изучим в одной из следующих глав.

Предлагаю немного повозиться. Если вы еще не запустили сервер и оболочку, самое время сделать это. Оболочка выполняет JavaScript. В ней есть несколько глобальных команд, таких как `help` или `exit`. Команды, выполняемые на текущей базе данных, выполняются на объекте `db`, что-то в духе `db.help()` или `db.stats()`. Команды на определенной коллекции (которые нам нужны чаще всех), выполняются на объекте `db.COLLECTION_NAME` - `db.unicorns.help()` или `db.unicorns.count()`.

Введите в оболочке команду `db.help()`, и вы получите список команд, которые можно выполнить на объекте `db`.

Небольшое отступление. Поскольку в оболочке у нас JavaScript, если вы выполните метод и забудете про скобки `()`, вам вернется тело метода, а не результат его выполнения. Я говорю об этом, чтобы когда вы в первый раз сделаете так и увидите ответ, начинающийся с `function(...){`, вы не очень пугались. Например, если вы напишете `db.help` (без скобок), вы получите код метода `help`.

Для начала мы воспользуемся глобальным методом `use` для переключения базы данных. Введите `use learn`. Не важно, что упомянутая база данных на самом деле не существует: как только мы создадим в ней первую коллекцию, мы одновременно создадим и БД `learn`. Теперь, находясь внутри базы данных, мы можем выполнять специфичные для базы команды, такие как `db.getCollectionNames`. Сделав это, вы получите пустой массив (`[ ]`). Поскольку коллекции бессхемны, нам не нужно явно создавать их. Мы можем просто вставить документ в новую коллекцию. Для этого у нас есть команда `insert`, которой мы передаем создаваемый документ:

	db.unicorns.insert({name: 'Aurora', gender: 'f', weight: 450})

Этой строкой мы осуществляем вставку (`insert`) на коллекции `unicorns`, передавая методу единственный аргумент. Внутри MongoDB использует двоичный сериализованный JSON.  Внешне же это означает, что нам придется часто использовать JSON, как в случае с нашим параметром. Если мы теперь выполним `db.getCollectionNames()`, мы получим целых две коллекции - `unicorns` и `system.indexes`. `system.indexes` создается единожды в каждой базе данных и хранит сведения о ее индексах.

Теперь на `unicorns` можно выполнить команду `find` и получить список документов:

	db.unicorns.find()

Обратите внимание, что кроме введенных вами данных, есть еще поле `_id`. Каждый документ должен иметь уникальное поле `_id`. Вы можете генерировать его самостоятельно или позволить MongoDB создавать ObjectId за вас. Чаще всего вы будете доверять это MongoDB. По умолчанию, поле `_id` проиндексировано - это и объясняет появление коллекции `system.indexes`. Можно посмотреть и на неё:

	db.system.indexes.find()

Вы получите имя индекса, базу данных и коллекцию, для которой он создан, а также поля, входящие в индекс.

Теперь мы вернемся к обсуждению бессхемных коллекций. Давайте, вставим совсем другой документ в коллекцию `unicorns`, как-то так:

	db.unicorns.insert({name: 'Leto', gender: 'm', home: 'Arrakeen', worm: false})

Попробуйте снова выполнить `find`, чтобы перечислить документы. Когда мы узнаем чуть больше, мы обсудим это необычное поведение MongoDB, но, надеюсь, вы уже начинаете понимать, почему традиционная терминология не очень подходит нам.

### Создание селекторов ###
В дополнение к уже исследованным 6 понятиям, есть ещё один практический аспект MongoDB, который важно понять прежде, чем переходить к более сложным вещам: селекторы запросов. Селекторы запросов в MongoDB похожи на `where` в SQL. Они используются для поиска, подсчёта, обновления и удаления документов из коллекций. Селектор есть JSON-объект, в своём простейшем виде выглядящий как `{}` и совпадающий со всеми документами (`null` тоже работает). Если мы хотим найти всех единорогов женского пола, мы можем использовать `{gender: 'f'}`.

Прежде, чем окончательно зарыться в селекторы, давайте подготовим немного данных, с которыми нам предстоит возиться. Для начала удалите все, что мы уже насоздавали в коллекции `unicorns` с помощью `db.unicorns.remove()` (поскольку мы не передали никакого селектора, этот вызов уничтожит все документы). Теперь выполните следующие insert-ы, чтобы ввести данные для упражнений (копирование и вставка поможет):

	db.unicorns.insert({name: 'Horny', dob: new Date(1992,2,13,7,47), loves: ['carrot','papaya'], weight: 600, gender: 'm', vampires: 63});
	db.unicorns.insert({name: 'Aurora', dob: new Date(1991, 0, 24, 13, 0), loves: ['carrot', 'grape'], weight: 450, gender: 'f', vampires: 43});
	db.unicorns.insert({name: 'Unicrom', dob: new Date(1973, 1, 9, 22, 10), loves: ['energon', 'redbull'], weight: 984, gender: 'm', vampires: 182});
	db.unicorns.insert({name: 'Roooooodles', dob: new Date(1979, 7, 18, 18, 44), loves: ['apple'], weight: 575, gender: 'm', vampires: 99});
	db.unicorns.insert({name: 'Solnara', dob: new Date(1985, 6, 4, 2, 1), loves:['apple', 'carrot', 'chocolate'], weight:550, gender:'f', vampires:80});
	db.unicorns.insert({name:'Ayna', dob: new Date(1998, 2, 7, 8, 30), loves: ['strawberry', 'lemon'], weight: 733, gender: 'f', vampires: 40});
	db.unicorns.insert({name:'Kenny', dob: new Date(1997, 6, 1, 10, 42), loves: ['grape', 'lemon'], weight: 690,  gender: 'm', vampires: 39});
	db.unicorns.insert({name: 'Raleigh', dob: new Date(2005, 4, 3, 0, 57), loves: ['apple', 'sugar'], weight: 421, gender: 'm', vampires: 2});
	db.unicorns.insert({name: 'Leia', dob: new Date(2001, 9, 8, 14, 53), loves: ['apple', 'watermelon'], weight: 601, gender: 'f', vampires: 33});
	db.unicorns.insert({name: 'Pilot', dob: new Date(1997, 2, 1, 5, 3), loves: ['apple', 'watermelon'], weight: 650, gender: 'm', vampires: 54});
	db.unicorns.insert({name: 'Nimue', dob: new Date(1999, 11, 20, 16, 15), loves: ['grape', 'carrot'], weight: 540, gender: 'f'});
	db.unicorns.insert({name: 'Dunx', dob: new Date(1976, 6, 18, 18, 18), loves: ['grape', 'watermelon'], weight: 704, gender: 'm', vampires: 165});

Теперь у нас есть данные, и мы можем начать создавать селекторы. `{field: value}` предназначен для поиска документов, где значение поля `field` совпадает с `value`. `{field1: value1, field2: value2}` - это как бы `and`. Операторы `$lt`, `$lte`, `$gt`, `$gte` и `$ne` - это «меньше», «меньше или равно», «больше», «больше или равно», «не равно» соответственно. Например, чтобы найти всех самцов-единорогов, весящих более 700 фунтов, мы можем выполнить:

	db.unicorns.find({gender: 'm', weight: {$gt: 700}})

или (не совсем то же самое, но для демонстрации подойдёт):

	db.unicorns.find({gender: {$ne: 'f'}, weight: {$gte: 701}})

Оператор `$exists` для поиска существующего или несуществующего поля:

	db.unicorns.find({vampires: {$exists: false}})

Должно вернуть один документ. Если мы хотим объединять условия по ИЛИ, а не по И, мы используем оператор `$or`, присваивая ему массив значений, которые мы хотим объединить:

	db.unicorns.find({gender: 'f', $or: [{loves: 'apple'}, {loves: 'orange'}, {weight: {$lt: 500}}]})

Это должно вернуть всех самок единорогов, которые либо любят яблоки, либо апельсины, либо весят менее 500 фунтов.

В примере выше есть еще один примечательный момент. Возможно, вы уже заметили, что поле `loves` - это массив. MongoDB считает массивы первоклассными объектами. Это невероятно удобная штука. Однажды начав ею пользоваться, вы будете удивляться, как раньше вы могли жить без неё. Ещё интереснее то, насколько легка выборка значений на основе массивов: `{loves: 'watermelon'}` вернёт все документы, где `watermelon` есть среди значений `loves`.

На самом деле, операторов много больше, чем мы тут обсудили. Самый гибкий из них - это `$where`, который позволяет передать JavaScript-код, выполняемый на сервере. Все операторы описаны на странице [Advanced Queries](http://www.mongodb.org/display/DOCS/Advanced+Queries#AdvancedQueries) на сайте MongoDB. Мы же рассмотрели лишь основы, необходимые для старта. Но одновременно это и самые востребованные операторы.

Мы видели, как селекторы могут использоваться в команде `find`. Точно так же они могут использоваться с `remove`, которую мы уже видели, `count`, которую мы не рассматривали, но вы, возможно, уже заметили, и `update`, с которой мы вплотную познакомимся чуть позже.

`ObjectId`, который MongoDB генерирует для наших `_id`, можно выбрать с помощью:

	db.unicorns.find({_id: ObjectId("TheObjectId")})

### В этой главе ###

Мы не рассматривали ещё команду `update` и пропустили несколько интересных фишек с `find`. Однако мы установили и запустили MongoDB, коротко познакомились с командами `insert` и `remove` (на самом деле, нам про них уже почти всё известно). Мы рассмотрели команду `find` и увидели, как работают селекторы в MongoDB. Мы неплохо начали и обзавелись неплохой основой для наших будущих исследований. Хотите - верьте, хотите - нет, но вы уже знаете большую часть того, что вам нужно знать о MongoDB - её действительно легко изучить и просто использовать. Я настоятельно советую вам поиграть с вашей базой данных перед тем, как двинуться дальше. Вставьте разных документов, возможно - в другие коллекции, и познакомьтесь поближе с различными селекторами. Используйте `find`, `count` и `remove`. Через некоторое время вещи, которые казались странными и непонятными, уложатся в картинку.

\clearpage

## Глава 2 - Обновление ##
В первой главе мы познакомились с тремя из четырёх CRUD-операций (create, read, update и delete). Эта глава посвящена оставшейся - `update`. У операции `update` есть несколько неожиданных особенностей, поэтому ей и посвщена целая глава.

### Обновление: Замена против $set ###
В своей простейшей форме `update` принимает два аргумента: селектор (where) для нужных документов и какое поле нужно обновить. Если Roooooodles немного набрал вес, мы выполним:

	db.unicorns.update({name: 'Roooooodles'}, {weight: 590})

(если вы играли с коллекцией `unicorns` и она уже не содержит нужных данных, просто снесите из неё все записи и выполните заново код из первой главы).

В реальном коде вы, возможно, использовали бы `_id` для выбора полей, но поскольку я не знаю, какие `_id` сгенерировала для вас MongoDB, мы будем использовать `name`. Давайте же посмотрим на обновлённую запись:

	db.unicorns.find({name: 'Roooooodles'})

И вот вам сразу первый сюрприз от `update`. Ничего не нашлось, потому что второй параметр **заменил** исходный документ. Другими словами, `update` нашла документ по полю `name` и с чистой совестью заменила его целиком новым документом из второго параметра. Да, это не похоже на поведение `update` из SQL. В некоторых ситуациях это может быть полезным. Однако если вы хотите лишь изменить значение одного или нескольких полей, вам нужно использовать модификатор `$set`:

	db.unicorns.update({weight: 590}, {$set: {name: 'Roooooodles', dob: new Date(1979, 7, 18, 18, 44), loves: ['apple'], gender: 'm', vampires: 99}})

Это вернет потерянным полям прежние значениея. А поскольку мы не указали `weight`, оно затронуто не будет. Теперь выполним:

	db.unicorns.find({name: 'Roooooodles'})

Теперь мы получим то, что ожидали. Таким образом, правильный способ обновления веса выглядит так:

	db.unicorns.update({name: 'Roooooodles'}, {$set: {weight: 590}})

### Модификаторы update ###
В довесок к `$set`, у нас есть еще несколько модификаторов для разных интересных вещей. Эти модификаторы работают с полями, так что весь документ они не стирают. Например, модификатор `$inc` предназначен для изменения значения поля на какое-либо положительное или отрицательное число. Например, если Pilot-у ошибочно засчитали пару убитых вампиров, мы можем исправить это:

	db.unicorns.update({name: 'Pilot'}, {$inc: {vampires: -2}})

Если Aurora вдруг стала сладкоежкой, мы можем добавить значение в её список `loves` с помощью `$push`:

	db.unicorns.update({name: 'Aurora'}, {$push: {loves: 'sugar'}})

Раздел [Updating](http://www.mongodb.org/display/DOCS/Updating) сайта MongoDB содержит больше информации об этих и других модификаторах

### Upsert-ы ###
Один из самых приятных сюрпризов `update` - это поддержка т.н. `upserts`. Это обновление документа если он существует или вставка нового в противном случае. Upsert-ы удобным в некоторых ситуациях, и вы это непременно заметите. Чтобы использовать эту фишку, нужно лишь добавить третьим параметром `true`.

Житейский пример - счётчик посещений на сайте. Если мы хотим хранить количество посещений, нам нужно посмотреть, есть ли уже запись для нужной странички, и решить, одновить её или создать новую. Без третьего параметра (или если он установлен в `false`), следующий код не сделает ничего полезного:

	db.hits.update({page: 'unicorns'}, {$inc: {hits: 1}});
	db.hits.find();

Однако, с использованием upsert-ов, результат будет иным:

	db.hits.update({page: 'unicorns'}, {$inc: {hits: 1}}, true);
	db.hits.find();

Поскольку до сих пор не существовало документа, у которого `page` было бы равно `unicorns`, будет создан новый. Если мы выполним то же самое ещё раз, `hits` у существующего документа увеличится до 2.

	db.hits.update({page: 'unicorns'}, {$inc: {hits: 1}}, true);
	db.hits.find();

### Множественные обновления ###
И последний сюрприз, приготовленный нам `update`, заключается в том, что по умолчанию обновляется только один документ. Для предыдущих примеров это выглядело логичным. Однако, если вы выполните что-то в духе:

	db.unicorns.update({}, {$set: {vaccinated: true }});
	db.unicorns.find({vaccinated: true});

Вы, вероятно, ожидаете увидеть всех ваших драгоценных единорогов привитыми. На самом деле, для этого нужно установить в `true` четвертый параметр:
 
	db.unicorns.update({}, {$set: {vaccinated: true }}, false, true);
	db.unicorns.find({vaccinated: true});

### В этой главе ###
Эта глава завершает наше знакомство с CRUD-операциями, которые можно выполнять с коллекциями. Мы поближе познакомились с `update` и рассмотрели три интересных возможности. Во-первых, в отличие от обновлений в SQL, `update` в MongoDB заменяет исходный документ. Из-за этого модификатор `$set` оказывается оень полезным. Во-вторых, `update` дает нам возможность использовать upsert-ы, что особенно удобно вместе с модификатором `$inc`. И, наконец, по умолчанию `update` обновляет только первый из найденных документов.

Не забывайте, что сейчас мы рассматриваем MongoDB с точки зрения работы через оболочку. Используемые вами драйверы и библиотеки могут иметь другие умолчания или даже предоставлять иные API. Например, дрыйвер для Ruby объединяет последние два параметра в хэш: `{:upsert => false, :multi => false}`.

\clearpage

## Глава 3 - Поиск документов ##
В первой главе мы уже кратко взглянули на команду `find`. Однако, её возможности не ограничиваются селекторами. Мы уже упоминали, что результатом работы `find` является курсор. Давайте же посмотрим более детально, что к чему.

### Выбор полей ###
Прежде, чем вплотную заняться курсорами, вам следует знать, что `find` принимает второй аргумент. Например, мы можем найти только имена всех единорогов:

	db.unicorns.find(null, {name: 1});

По умолчанию, в ответе всегда будет поле `_id`. Но мы можем явно исключить его, указав `{name:1, _id: 0}`.

Кроме поля `_id` смешивать включение и исключение других полей нельзя. Если вы думали об этом, то это важно. Вам следует явно либо выбирать, либо исключать поля.

### Сортировка ###
Я уже неоднократно упоминал, что `find` возвращает курсор, реальное выполнение которого откладывается до победного. Однако, как вы, несомненно заметили, работая с оболочкой, `find` выполняется сразу же. Такое поведение характерно только для оболочки. Истинное поведение курсоров можно увидеть, взглянув на методы, которые можно сцепить с `find`. Первый из них - это `sort`. Он работает подобно выбору полей из предыдущего раздела. Мы указываем поля, по которым сортировать, и 1 для сортировки по возрастанию либо -1 - по убыванию. Например:

	//heaviest unicorns first
	db.unicorns.find().sort({weight: -1})
	
	//by vampire name then vampire kills:
	db.unicorns.find().sort({name: 1, vampires: -1})

Как и реляционные базы данных, MongoDB может использовать индексы при сортировке. С индексами мы познакомимся чуть позже. Однако, важно знать, что MongoDB ограничивает размер сортировки без индекса. Таким образом, при попытке отсортировать большую выборку без индекса, мы получим ошибку. Некоторые считают это ограничением. По правде говоря, я бы хотел, чтобы у всех СУБД была возможность запрещать выполнение неоптимизированных запросов (я не пытаюсь превратить каждый недостаток MongoDB в достоинство, но я достаточно насмотрелся на плохо оптимизированные БД и искренне мечтаю, чтобы в них была какая-либо строгость).

### Разбиение на страницы ###
Разбиение результата на страницы выполняется с помощью методов `limit` и `skip` курсора. Чтобы выбрать второго и третьего по весу единорога, сделаем:

	db.unicorns.find().sort({weight: -1}).limit(2).skip(1)

Использование `limit` в связке с `sort` - хороший способ избежать проблем при сортировке по неиндексированным полям

### Подсчёт ###
Оболочка позвлоляет выполнить `count` прямо на коллекции, как-то так:

	db.unicorns.count({vampires: {$gt: 50}})

В реальности же `count` - это метод курсора, в оболочку же просто встроен костыль для этого. Драйверы, не имеющие такой плюшки, требуют такого подхода (в оболочке тоже работает):

	db.unicorns.find({vampires: {$gt: 50}}).count()

### В этой главе ###
Использование `find` и курсоров - это явное преимущество. Есть еще несколько дополнительных команд, которые мы либо рассмотрим в дальнейших главах, либо которые предназначены для специфичных задач. Сейчас же вы уже должны достаточно комфортно чувствовать себя в оболочке mongo и понимать основы MongoDB/

\clearpage

## Глава 4 - Моделирование данных ##
Предлагаю перейти к немного более абстрактной теме, касающейся MongoDB. Объяснить неколько новых терминов и немного нового синтаксиса - не самая сложная задача. Рассмотреть особенности моделирования с новой парадигмой - на порядок сложнее. На самом деле, многие из нас продолжают методом проб и ошибок искать правильный подход к моделированию в этих новых технологиях. Мы лишь начнем этот разговор, но большую часть этой темы вам придется раскрыть самостоятельно, работая с реальным кодом.

По сравнению с другими NoSQL-решениями, документ-ориентированные БД, возможно, меньше всего отличаются от реляционных в плане моделирования. Разница не велика, но это не значит, что ею можно пренебречь.

### Никаких объединений ###
Первое и самое важное отличие, которое нужно усвоить для комфортной работы с MongoDB - это отсутствие джойнов. Я не знаю точной причины, почему некоторые возможности джойнов не поддерживаются в MongoDB, но я точно знаю, что джойны масштабируются примерно никак. Таким образом, однажды начав разделять свои данные горизонтально, вы дойдете до выполнения джойнов на клиенте (т.е. в сервере приложений). Независимо от причин, остается фактом то, что данные *являются* реляционными, а MongoDB не поддерживает джойны.

Не имея ничего другого и живя в мире без объединений, мы вынуждены выполнять их самостоятельно, из кода нашего приложения. Мы всего лишь должны выполнить еще один `find` за нужными данными. Отличий от объявления внешнего ключа не много. Давайте немного отвлечемся от единорогов и взглянем на сотрудников. Для начала мы создадим одного (я явно указываю `_id`, чтобы вы могли использовать дальнейшие примеры без изменений):

	db.employees.insert({_id: ObjectId("4d85c7039ab0fd70a117d730"), name: 'Leto'})

Давайте добавим еще сотрудников, и назначим Leto их руководителем:

	db.employees.insert({_id: ObjectId("4d85c7039ab0fd70a117d731"), name: 'Duncan', manager: ObjectId("4d85c7039ab0fd70a117d730")});
	db.employees.insert({_id: ObjectId("4d85c7039ab0fd70a117d732"), name: 'Moneo', manager: ObjectId("4d85c7039ab0fd70a117d730")});

(Не будет лишним напомнить, что значения `_id` должны быть уникальными. Поскольку вы, скорее всего, будете использовать `ObjectId` в своих приложениях, здесь тоже будет он)

Конечно же, чтобы найти всех подчинённых Leto, можно просто выполнить:

	db.employees.find({manager: ObjectId("4d85c7039ab0fd70a117d730")})

Вот и всё, никакой магии. В худшем случае, отсутствие соединений будет требовать лишь дополнительного запроса (индексированного, пожалуй).

#### Массивы и внедрённые документы ####
То, что MongoDB не умеет джойны, ещё не означает, что у неё нет других хитростей. Помните, мы немного говорили о том, что MongoDB поддерживает массивы как первоклассные объекты? Это же невероятно удобно, когда нам надо организовать отношения многие-к-одному и многие-ко-многим. В качестве простого примера, если у сотрудника может оказаться два руководителя, мы просто положим их в массив:

	db.employees.insert({_id: ObjectId("4d85c7039ab0fd70a117d733"), name: 'Siona', manager: [ObjectId("4d85c7039ab0fd70a117d730"), ObjectId("4d85c7039ab0fd70a117d732")] })

В качестве дополнительной плюшки, `manager` для некоторых документов может быть скалярным значением, а для некоторых - массивом. Наш `find` прекрасно отработает в обоих случаях:

	db.employees.find({manager: ObjectId("4d85c7039ab0fd70a117d730")})

Полагаю, вы быстро обнаружите, что массивы значений гораздо более удобны, чем эти ваши таблицы с джойнами.

Помимо массивов, MongoDB также поддерживает внедрённые документы. Попробуйте создать документ с внедрённым документом, вот так:

	db.employees.insert({_id: ObjectId("4d85c7039ab0fd70a117d734"), name: 'Ghanima', family: {mother: 'Chani', father: 'Paul', brother: ObjectId("4d85c7039ab0fd70a117d730")}})

И, как вы, вероятно, уже подумали, внедрённый документ можно запросить, используя точечную нотацию:

	db.employees.find({'family.mother': 'Chani'})

Давайте кратко побеседуем о том, в каких случаях пригодятся внедрённые документы и как их использовать.

#### DBRef ####
MongoDB поддерживает нечто, именуемое `DBRef`, и это соглашение поддерживают многие драйверы. Когда драйвер встречает `DBRef`, он автоматически подтягивает ссылаемый документ. `DBRef` включает в себя коллекцию и идентификатор ссылаемого документа. Это, в основном, служит одной специфичной цели: когда документы из одной коллекции ссылаются на документы из другой, и наоборот. Таким образом, `DBRef` для документа document1 может указывать на документ в `managers`, а `DBRef` из document2 может указывать на документ из `employees`.

#### Денормализация ####
Ещё одной альтернативой джойнам является денормализация данных. Исторически, денормализация применялась лишь для весьма чувствительного к производительности кода, или когда данные нужно было действительно дублировать (как в журналах аудита). Однако, с ростом популярности NoSQL, многие из которых не умеют джойны, денормализация всё чаще становится частью обычного процесса моделирования. Это не значит, что нужно дублировать вообще все данные в каждом документе. Но, вместо того, чтобы бояться дублирования в своих моделях, просто обращайте внимение на то, где и что хранить.

Для примера допустим, что вы разрабатываете движок форума. Традиционный способ связать определенного пользователя с постом - это добавить в `posts` колонку `user_id`. В такой модели вы не можете отобразить посты, не запрашивая (т.е., без объединения) пользователей. Возможной альтернативой будет хранение имени вместе с `user_id` в каждом посте. Можно даже использовать внедрённый документ для этого: `user: {id: ObjectId('Something'), name: 'Leto'}`. Разумеется, если вы разрешаете юзерам менять свои имена, вам придётся в таких случаях обновлять все посты (что есть еще один дополнительный запрос).

Иногда приспособиться к такому подходу бывает непросто. В некоторых случаях будет даже непонятно, нужен ли он. Не бойтесь экспериментировать. Он не только подходит для некоторых ситуаций, но и является единственно верным.

#### Что же выбрать? ####
Массивы идентификаторов - это всегда полезная стратегия, когда приходится работать с отношениями один-ко-многим и многие-ко-многим. Можно даже сказать, что `DBRef` используется довольно редко, хотя вы, конечно же, можете повозиться и с ними. Этот момент обычно оставляет начинающих разработчиков в непонятках, использовать ли внедрённые документы или просто ссылаться.

Первое, что нужно знать - это то, что каждый отдельный документ ограничен в размерах до 4 мегабайт. Знание, что документы имеют ограничения, пусть и достаточно большие, подсказывает нам, как их лучше использовать. Сейчас будет казаться, что большинство разработчиков делают больший упор на ссылки для своих отношений. Внедренные документы тоже часто используются, но лишь для хранения небольших кусочков данных, которые непременно надо таскать вмете с объемлющим документом. В качестве живого примера я использую документов `accounts` вместе с каждым пользователем, как-то так:

	db.users.insert({name: 'leto', email: 'leto@dune.gov', account: {allowed_gholas: 5, spice_ration: 10}})

Это не означает, что нужно недооценивать мощь внедрённых документов и использовать их как что-то менее полезное. Проецирование модели данных на объекты реального мира упрощает принятие решений и часто избавляет от нужды в джойнах. Это будет особенно верно, когда вы увидите, что MongoDB позволяет запрашивать и индексировать поля внедрённых документов.

### Мало или много коллекций ###
Зная, что коллекции не имеют никакой схемы, возможно построить систему с единственной коллекцией, хранящей совсем разношёрстные документы. Но по моим личным наблюдениям, системы в MongoDB чаще строятся аналогично реляционным системам: то, что в РБД было бы таблицей, будет коллекцией в MongoDB (таблицы для отношений многие-ко-многим - это важное исключение).

Беседа становится интереснее, когда вы переходите к внедрённым документам. Часто вспоминаемый при этом пример - это блог. Следует ли нам иметь коллекцию `posts` и коллекцию `comments`, или посты должны иметь массив внедрённых в них комментов? Памятуя об ограничении в 4 мегабайта (весь "Гамлет" весит меньше 200 килобайт, напишут ли вам столько комментов?), большинство разработчиков предпочтут разделить коллекции. Это более ясно и чётко.

Жёстких правил не существует (ну, кроме всё тех же 4 МБ). Попробуйте применять различные подходы, и вы поймёте, что в вашем случае хорошо, а что - нет.

### В этой главе ###
Нашей целью в этой главе было предоставить несколько полезных идей для моделирования ваших данных в MongoDB. Отправная точка, ежели угодно. Моделирование в документ-ориентированной системе отличается, но не радикально, от реляционного мира. Вы получаете большую гибкость и одно ограничение, но для новых систем всё просто идеально. Единственный ошибочный подход - это не пытаться делать что-либо.

\clearpage

## Глава 5 - Когда использовать MongoDB ##
К этому моменту у вас уже должно было сложиться хорошее понимание того, как вы сможете использовать MongoDB в ваших существующих системах. От количества новых технологий хранения даже голова может закружиться.

Для меня лично самый важный урок - это то, что больше не нужно завязываться на единственное решение для хранения данных. Несомненно, единственное хранилище имеет неоспоримые преимущества, и для множества (пожалуй, даже большинства) проектов оно будет оптимальным подходом. Идея не в том, что вы должны использовать различные технологии, но в том, что вы можете это сделать. Только вы можете решить, когда стоит добавлять еще одно решение.

С учётом всего сказанного, я надеюсь, что вы видите MongoDB как решение общего назначения. Мы уже упоминали несколько раз, что документ-ориентированные БД имеют много общего с реляционными. Вместо того, чтобы играть словами, давайте просто договоримся, что MongoDB можно рассматривать как прямую альтернативу реляционным базам. Там, где кто-то видит Lucene как улучшение для полнотекстовых индексов, или Redis как персистентное хранилище ключ-значение, MongoDB будет центральным хранилищем ваших данных.

Прошу заметить, что я назвал MongoDB не *заменой* реляционных БД, но *альтернативой* им. Это инструмент, который может делать то же самое, что и все остальные. Что-то MongoDB делает лучше, что-то - хуже. Давайте разберёмся, что именно.

### Отсутствие схемы ###
Одним из самых часто упоминаемых преимуществ документ-ориентированных баз является отсутствие схемы. Это делает их много более гибкими, чем традиционные таблицы. Я согласен, что бессхемность - это удобная штука, но совсем не по той причине, которая многими упоминается.

Люди говорят о бессхемности как если бы вы вдруг стали хранить чумовую мешанину данных. Существуют такие области и наборы данных, которые действительно трудно смоделировать для реляционных БД, но это же только крайние случаи. Бессхемность - это здорово, но большая часть ваших данных так или иначе структурирована. Согласен, иметь отдельные расхождения удобно, особенно при добавлении нового функционала, но в реальности нет ничего, что бы нельзя было решить с помощью столбцов, допускающих пустые значения.

Для меня, реальными преимуществами бессхемности являются более простая настройка и лёгкость связывания с ООП. Это особенно верно, когда вы работаете со статическими языками. Я работал с MongoDB в C# и Ruby, и разница впечатляет. Динамизм Ruby и его популярная библиотека ActiveRecord сами по себе уменьшают трудности связи данных и объектов. Я не хочу сказать, что MongoDB не подходит для Ruby, ещё как подходит. Многие Ruby-разработчики увидят в MongoDB просто улучшение, тогда как программисты на C# или Java заметят серьёзные различия в подходе к работе с данными.

Подумайте об этом с точки зрения разработчика драйвера. Вы хотите сохранить объект? Сериализуйте его в JSON (на самом деле, BSON, но разница не велика) и отправьте его MongoDB. Не нужно никаких соответствия свойств и типов. Эта прямолинейность, определённо, влияет на вас, разработчиков.

### Writes ###
Есть одна задача, для которой MongoDB очень хорошо подходит - логирование. У неё есть две хитрости, делающие запись очень быстрой. Во-первых, команда на запись выполняется мгновенно, а не заставляет нас ждать, пока запись действительно произойдёт. Во-вторых, с представлением журналирования в версии 1.8 и улучшениями в 2.0, записью можно управлять для достижения нужной надёжности данных. Такие настройки, в дополнение к указанию, сколько серверов должны получить данные, прежде чем они будут считаться записанными успешно, можно указывать для каждой операции записи, что даёт нам возможность контролировать производительность записи и надёжность данных.

В довесок к высокой производительности, логирование также выигрывает от бессхемности коллекций. И, в конце концов, у MongoDB есть плюшка под названием [capped collection](http://www.mongodb.org/display/DOCS/Capped+Collections). По умолчанию все коллекции создаются обычными, мы можем сделать их capped, явно указав соответствующий флаг в `db.createCollection`:

	//limit our capped collection to 1 megabyte
	db.createCollection('logs', {capped: true, size: 1048576})

Когда наша коллекция дорастёт до 1 мегабайта, старые документы будут автоматически удалены. Можно также установить ограничение на количество документов, а не на объём, для этого есть `max`. У ограниченных коллекций есть ряд интересных свойств. Например, можно обновлять документ, но ему будет нельзя увеличиваться в размерах. Также, нам доступен порядок создания документов, поэтому нам не нужен индекс для сортировки по времени создания

Не будет лишним сказать, что если вам нужно знать, не случилось ли ошибок при записи (по умолчаниютони не выводятся), вы можете выполнить команду `db.getLastError()`. Многие драйверы добавляют метод для *безопасной записи*, указывая параметр `{:safe => true}` вторым параметром `insert`.

### Надёжность ###
До версии 1.8 в MongoDB не было обеспечения надёжности для единственного сервера. То есть, при падении сервера данные, скорее всего, терялись. Выходом из этой ситуации был запуск множества серверов (MongoDB умеет репликацию). Важной фишкой, добавленной в 1.8, стало журналирование. Чтобы включить его, добавьте строку `journal=true` в ваш `mongodb.config` который мы создали при установке (и не забудьте перезапустить сервер, чтобы он подхватил изменения). Скорее всего, вы захотите иметь журналирование включенным (в будущих релизах это будет по умолчанию). Однако, в некоторых обстоятельствах отключение журналирования может быть вполне оправданным риском (ведь некоторым приложениям не страшно терять данные).

Надёжность упоминается здесь лишь для того, чтобы рассказать, как много было сделано для преодоления ненадёжности единственного сервера. Информация о ненадежности, несомненно, ещё не раз попадётся вам на глаза. Просто учтите, что она протухла.

### Полнотекстовый поиск ###
Настоящий полнотекстовый поиск - это то, чего все ждут с надеждою от одного из будущих релизов MongoDB. Однако, благодаря поддержке массивов, простой полнотекстовый поиск можно легко собрать на коленке. Для чего-то более продвинутого придётся использовать сторонние решения, такие как Lucene или Solr. Многие реляционные базы, впрочем, тоже этим грешат.

### Транзакции ###
Транзакций в MongoDB нет. Но есть целых две альтернативы, одна из которых хороша, но ограничена, а вторая похуже, но более гибкая.

Первая - это наличие нескольких атомарных операций. В большинстве случаев их вполне достаточно. Некоторые из них мы уже видели - это `$inc` и `$set`. Есть ещё команды наподобие `findAndModify`, которые обновляют объекты и тут же их возвращают.

Вторая используется, когда атомарных операций недостаточно, и называется она "двухфазная запись". Двухфазная запись по отношению к настоящим транзакциям - это как расстановка ссылок вручную по отношению к джойнам. На сайте MongoDB [есть пример](http://www.mongodb.org/display/DOCS/two-phase+commit), иллюстрирующий довольно распространённый сценарий (перевод денег). Основная идея в том, что мы храним в документе состояние транзакции и выполняем начало-ожидание-подтверждение/откат ручками.

Поддержка вложенных документов и бессхемный дизайн делают двухфазную запись менее болезненной, но это всё равно не верх приятности, особенно для тех, кто впервые с этим сталкивается.

### Обработка данных ###
Для большинства задач обработки данных MongoDB использует MapReduce. [Кое-что](http://www.mongodb.org/display/DOCS/Aggregation) она умеет "из коробки", но для чего-то серьёзного без MapReduce не обойтись. В следующей главе мы рассмотрим MapReduce поближе. Пока же просто думайте об этом как о мощном и слегка необычном способе выполнить `group by`. Одной из сильных сторон MapReduce является его умение распараллеливать обработку больших объёмов данных. Однако сама MongoDB работает в основном на JavaScript, который однопоточен. Выход? Для обработки больших наборов нужно обратиться к чему-то другому, например, к Hadoop. Благодаря тому, что системы задуманы как дополняющие друг друга, у нас есть [адаптер MongoDB-Hadoop](https://github.com/mongodb/mongo-hadoop).

Разумеется, параллельная обработка данных не является сильной стороной и большинства реляционных СУБД. В планах на будущие релизы MongoDB есть и улучшение работы с большими наборами данных.

### Geospatial ###
Особенно мощная штука, имеющаяся в MongoDB - это поддержка гео-индексов. Они позволяют нам хранить координаты (x и y) в документе, а потом искать то, что рядом (`$near`) с нужными нам координатами или внутри (`$within`) определенного круга или квадрата. Это всё лучше объяснять наглядно, поэтому я приглашаю вас посетить [5 minute geospatial interactive tutorial](http://tutorial.mongly.com/geo/index), если вас эта тема заинтересовала.

### Инструменты и зрелость ###
Возможно, вы и так уже всё знаете: MongoDB значительно моложе большинства реляционных СУБД. Это нельзя отрицать. Насколько это важно - зависит от того, что вы делаете и как вы это делаете. Но, по-хорошему, нельзя игнорировать то, что MongoDB весьма молода, и инструментов для неё пока немного (впрочем, у некоторых зрелых СУРБД дела обстоят не лучше). Например, отсутствие поддержки десятичных чисел с плавающей точкой может стать проблемой (не факт, что непреодолимой), когда системе надо работать с деньгами.

On the positive side, drivers exist for a great many languages, the protocol is modern and simple, and development is happening at blinding speeds. MongoDB is in production at enough companies that concerns about maturity, while valid, are quickly becoming a thing of the past.

С другой стороны, существуют драйверы для очень многих языков, протокол соверменен и прост, а разработка ведётся с космической скоростью. НИПАНИМАТ Я ВАШ АНГЛИЙСКИЙ, ПЕРЕВЕДИТЕ КТО-НИБУДЬ ЭТУ ФРАЗУ, А?

### В этой главе ###
The message from this chapter is that MongoDB, in most cases, can replace a relational database. It's much simpler and straightforward; it's faster and generally imposes fewer restrictions on application developers. The lack of transactions can be a legitimate and serious concern. However, when people ask *where does MongoDB sit with respect to the new data storage landscape?* the answer is simple: **right in the middle**.

Эта глава стремится донести мысль о том, что MongoDB в большинстве случаев может заменить реляционные базы данных. Она более проста и прямолинейна, она быстрее и накладывает меньше ограничений на разработчиков. Отсутствие транзакций может оказаться серьёзноым недостатком. Однако, когда кто-либо спрашивает: *"где находится MongoDB в современном мире хранения данных?"*, ответ будет прост: **"точно посередине"**.

\clearpage

## Глава 6 - MapReduce ##
MapReduce - это подход к обработке данных, имеющий два важных преимущества перед традиционными решениями. Первое (и самое важное) - он был разработан для высокой производительности. Теоретически, MapReduce может распараллеливаться, позволяя обрабатывать большие объёмы данных на нескольких ядрах/процессорах/машинах. Как мы уже и говорили, MongoDB пока не справляется с этим. Второе преимущество MapReduce заключается в том, что для обработки вы можете писать настоящий код. По сравнению с возможностями SQL, MapReduce даёт гораздо больше возможностей, и значительно отодвигает тот момент, когда вам придётся обратиться к более специализированным решениям.

MapReduce - это набирающий популярность паттерн, и его можно использовать почти где угодно. Существуют реализации для C#, Ruby, Java, Python, и многих других языков. Хочу предупредить, что поначалу всё будет казаться непривычным и сложным. Не пугайтесь, найдите время, чтобы повозиться с этим самостоятельно. Это полезно понимать независимо от тог, используете ли вы MongoDB или нет.

### Смесь из теории и практики ###
MapReduce - это процесс, состоящий из двух этапов. Сначала вы распределяете (map), а затем - сворачиваете (reduce). При распределении входные документы разбираются на пары ключ=>значение (и то, и другое может быть сложным). Свёртка берёт ключ и массив значений для этого ключа, и вычисляет конечный результат. Мы рассмотрим каждый шаг и то, что выводится на каждом шаге.

Для нашего примера мы будем генерировать отчёт о количестве посещений страницы веб-сайта за один день. Это такой *hello world* для MapReduce. Для нашей задачи мы возьмём коллекцию `hits`, имеющую два поля: `resource` и `date`. Мы хотим, чтобы выдача делилась на ресурс, год, месяц, число и количество.

Пусть в `hits` у нас будут следующие данные:

	resource     date
	index        Jan 20 2010 4:30
	index        Jan 20 2010 5:30
	about        Jan 20 2010 6:00
	index        Jan 20 2010 7:00
	about        Jan 21 2010 8:00
	about        Jan 21 2010 8:30
	index        Jan 21 2010 8:30
	about        Jan 21 2010 9:00
	index        Jan 21 2010 9:30
	index        Jan 22 2010 5:00

А получить мы хотим вот такой результат:

	resource  year   month   day   count
	index     2010   1       20    3
	about     2010   1       20    1
	about     2010   1       21    3
	index     2010   1       21    2
	index     2010   1       22    1

(У этого подхода есть один приятный бонус: когда мы храним вывод, отчёты генерируются быстрее, а увеличение объема данных контролируется: для каждого отслеживаемого ресурса будет создаваться не более 1 документа в день).

Давайте пока сосредоточимся на понимании принципа. В конце главы я дам вам данные и код, с которыми вы сможете поиграть самостоятельно.

Сначала посмотрим на map-функцию. Её задача - выдавать значение, которое потом может быть свёрнуто. Она может выдавать результат 0 и более раз. В нашем случае (и в большинстве других) она выдаёт одно значение. Представьте себе, что map пробегает по всем документам в коллекции. Мы хотим выдавать для каждого документа ключ, состоящий из ресурса, года, месяца и дня, а значение его всегда должно быть 1:

	function() {
		var key = {
		    resource: this.resource, 
		    year: this.date.getFullYear(), 
		    month: this.date.getMonth(), 
		    day: this.date.getDate()
		};
		emit(key, {count: 1}); 
	}

`this` означает текущий обрабатываемый документ. Надеюсь, что изучение вывода поможет вам понять, что здесь происходит. Для данных, предложенных выше, вывод будет выглядеть вот так:

	{resource: 'index', year: 2010, month: 0, day: 20} => [{count: 1}, {count: 1}, {count:1}]
	{resource: 'about', year: 2010, month: 0, day: 20} => [{count: 1}]
	{resource: 'about', year: 2010, month: 0, day: 21} => [{count: 1}, {count: 1}, {count:1}]
	{resource: 'index', year: 2010, month: 0, day: 21} => [{count: 1}, {count: 1}]
	{resource: 'index', year: 2010, month: 0, day: 22} => [{count: 1}]

Понимание этого промежуточного шага - это ключ к пониманию MapReduce. Значения из выдачи сгруппированы в массивы по ключу. Программисты .NET и Java могут думать о них как о `IDictionary<object, IList<object>>` (для .NET) или `HashMap<Object, ArrayList>` (для Java).

Давайте слегка изменим нашу map-функцию:

	function() {
		var key = {resource: this.resource, year: this.date.getFullYear(), month: this.date.getMonth(), day: this.date.getDate()};
		if (this.resource == 'index' && this.date.getHours() == 4) {
			emit(key, {count: 5});
		} else {
			emit(key, {count: 1}); 
		}
	}

И первый промежуточный вывод станет таким:

	{resource: 'index', year: 2010, month: 0, day: 20} => [{count: 5}, {count: 1}, {count:1}]

Обратите внимание, как emit генерирует новые значения, которыегруппируются по ключу.

Функция свёртки принимает каждый из этих промежуточных результатов и выводит конечный результат. Наша будет выглядеть вот так:

	function(key, values) {
		var sum = 0;
		values.forEach(function(value) {
			sum += value['count'];
		});
		return {count: sum};
	};

И выведет она:

	{resource: 'index', year: 2010, month: 0, day: 20} => {count: 3}
	{resource: 'about', year: 2010, month: 0, day: 20} => {count: 1}
	{resource: 'about', year: 2010, month: 0, day: 21} => {count: 3}
	{resource: 'index', year: 2010, month: 0, day: 21} => {count: 2}
	{resource: 'index', year: 2010, month: 0, day: 22} => {count: 1}

Технически, вывод в MongoDB будет таким:

	_id: {resource: 'home', year: 2010, month: 0, day: 20}, value: {count: 3}

Думаю, вы уже заметили, что мы добились того, чего хотели.

Если вы были очень внимательны, то вы, возможно, спросите себя: *"а почему нельзя просто использовать `sum = values.length`?"*. Это может показаться более эффективным, особенно при сложении массива из единичек. Вот только reduce не всегда вызывается на полном и правильном наборе промежуточных данных. Например, вместо:

	{resource: 'home', year: 2010, month: 0, day: 20} => [{count: 1}, {count: 1}, {count:1}]

reduce может получить:

	{resource: 'home', year: 2010, month: 0, day: 20} => [{count: 1}, {count: 1}]
	{resource: 'home', year: 2010, month: 0, day: 20} => [{count: 2}, {count: 1}]

В конце мы всё равно получим 3, но несколько иным путём. Таким образом, reduce всегда должна быть идемпотентна. То есть, сколько бы мы ни вызывали её, она всегда должна возвращать тот же результат.

Мы не будем раскрывать эту тему здесь, но часто встречаются ситуации, когда reduce-методы выполняются цепочкой для выполнения более сложного анализа.

### Только практика ###
Работая с MongoDB, мы выполняем функцию `mapReduce` на коллекции. `mapReduce` принимает аргументами map-функцию, reduce-функцию и директиву вывода. В оболочке мы можем создать JavaScript-функцию и передать её аргументом. Для большинства библиотек придётся писать в аргументе функцию в виде строки (выглядит ужасно). Однако же, давайте введём наш набор данных

	db.hits.insert({resource: 'index', date: new Date(2010, 0, 20, 4, 30)});
	db.hits.insert({resource: 'index', date: new Date(2010, 0, 20, 5, 30)});
	db.hits.insert({resource: 'about', date: new Date(2010, 0, 20, 6, 0)});
	db.hits.insert({resource: 'index', date: new Date(2010, 0, 20, 7, 0)});
	db.hits.insert({resource: 'about', date: new Date(2010, 0, 21, 8, 0)});
	db.hits.insert({resource: 'about', date: new Date(2010, 0, 21, 8, 30)});
	db.hits.insert({resource: 'index', date: new Date(2010, 0, 21, 8, 30)});
	db.hits.insert({resource: 'about', date: new Date(2010, 0, 21, 9, 0)});
	db.hits.insert({resource: 'index', date: new Date(2010, 0, 21, 9, 30)});
	db.hits.insert({resource: 'index', date: new Date(2010, 0, 22, 5, 0)});

Теперь создадим наши map- и reduce-функции (оболочка MongoDB принимает многострочные выражения, вы увидите *...* после нажатия Enter, если она ожидает ещё чего-то):

	var map = function() {
		var key = {resource: this.resource, year: this.date.getFullYear(), month: this.date.getMonth(), day: this.date.getDate()};
		emit(key, {count: 1}); 
	};
	
	var reduce = function(key, values) {
		var sum = 0;
		values.forEach(function(value) {
			sum += value['count'];
		});
		return {count: sum};
	};

И теперь мы можем использовать их в нашей команде `mapReduce` на коллекции `hits`, вот так:

	db.hits.mapReduce(map, reduce, {out: {inline:1}})

Когда вы выполните это, вы увидите желаемый вывод. Установка `out` в `inline` означает, что вывод `mapReduce` будет отправлен сразу вам. Так можно вывести только результат, не превышающий 16 мегабайт. Вместо этого мы можем сказать `{out: 'hit_stats'}`, и результат будет сохранён в коллекции `hit_stats`:

	db.hits.mapReduce(map, reduce, {out: 'hit_stats'});
	db.hit_stats.find();

Когда вы так сделаете, все существующие в `hit_stats` данные будут уничтожены. Если же указать `{out: {merge: 'hit_stats'}}`, значения существующих ключей будут заменены новыми, а новые ключи будут вставлены как новые документы. И наконец, мы можем выводить данные из `reduce`, чтобы осуществлять разные хитрости (наподобие upsert-ов).

В третьем параметре можно передать разные дополнительные опции. Например, мы можем отбирать, сортировать и лимитировать документы которые мы хотим анализировать. Также можно передать метод `finalize`, который будет выполнен на результирующем наборе после `reduce`.

### В этой главе ###
Это первая глава, в которой мы открыли что-то действительно необычное. Если вам это кажется неудобным, помните, что вы всегда можете воспользоваться другими [возможностями агрегации данных](http://www.mongodb.org/display/DOCS/Aggregation) в MongoDB для более простых сценариев. Как бы то ни было, MapReduce - это одна из самых серьёзных возможностей MongoDB. Ключ к пониманию того, как писать свои функции распределения и свёртки - это представлять и понимать, как промежуточные данные должны выглядеть на пути из `map` в `reduce`.

\clearpage

## Chapter 7 - Performance and Tools ##
In this last chapter, we look at a few performance topics as well as some of the tools available to MongoDB developers. We won't dive deeply into either topic, but we will examine the most import aspects of each.

### Indexes ###
At the very beginning we saw the special `system.indexes` collection which contains information on all the indexes in our database. Indexes in MongoDB work a lot like indexes in a relational database: they help improve query and sorting performance. Indexes are created via `ensureIndex`:

	db.unicorns.ensureIndex({name: 1});

And dropped via `dropIndex`:

	db.unicorns.dropIndex({name: 1});

A unique index can be created by supplying a second parameter and setting `unique` to `true`:

	db.unicorns.ensureIndex({name: 1}, {unique: true});

Indexes can be created on embedded fields (again, using the dot-notation) and on array fields. We can also create compound indexes:

	db.unicorns.ensureIndex({name: 1, vampires: -1});

The order of your index (1 for ascending, -1 for descending) doesn't matter for a single key index, but it can have an impact for compound indexes when you are sorting or using a range condition.

The [indexes page](http://www.mongodb.org/display/DOCS/Indexes) has additional information on indexes.

### Explain ###
To see whether or not your queries are using an index, you can use the `explain` method on a cursor:

	db.unicorns.find().explain()

The output tells us that a `BasicCursor` was used (which means non-indexed), 12 objects were scanned, how long it took, what index, if any was used as well as a few other pieces of useful information.

If we change our query to use an index, we'll see that a `BtreeCursor` was used, as well as the index used to fulfill the request:

	db.unicorns.find({name: 'Pilot'}).explain()

### Fire And Forget Writes ###
We previously mentioned that, by default, writes in MongoDB are fire-and-forget. This can result in some nice performance gains at the risk of losing data during a crash. An interesting side effect of this type of write is that an error is not returned when an insert/update violates a unique constraint. In order to be notified about a failed write, one must call `db.getLastError()` after an insert. Many drivers abstract this detail away and provide a way to do a *safe* write - often via an extra parameter.

Unfortunately, the shell automatically does safe inserts, so we can't easily see this behavior in action.

### Sharding ###
MongoDB supports auto-sharding. Sharding is an approach to scalability which separates your data across multiple servers. A naive implementation might put all of the data for users with a name that starts with A-M on server 1 and the rest on server 2. Thankfully, MongoDB's sharding capabilities far exceed such a simple algorithm. Sharding is a topic well beyond the scope of this book, but you should know that it exists and that you should consider it should your needs grow beyond a single server.

### Replication ###
MongoDB replication works similarly to how relational database replication works. Writes are sent to a single server, the master, which then synchronizes itself to one or more other servers, the slaves. You can control whether reads can happen on slaves or not, which can help distribute your load at the risk of reading slightly stale data. If the master goes down, a slave can be promoted to act as the new master. Again, MongoDB replication is outside the scope of this book.

 While replication can improve performance (by distributing reads), its main purpose is to increase reliability. Combining replication with sharding is a common approach. For example, each shard could be made up of a master and a slave. (Technically you'll also need an arbiter to help break a tie should two slaves try to become masters. But an arbiter requires very few resources and can be used for multiple shards.)

### Stats ###
You can obtain statistics on a database by typing `db.stats()`. Most of the information deals with the size of your database. You can also get statistics on a collection, say `unicorns`, by typing `db.unicorns.stats()`. Again, most of this information relates to the size of your collection.

### Web Interface ###
Included in the information displayed on MongoDB's startup was a link to a web-based administrative tool (you might still be able to see if if you scroll your command/terminal window up to the point where you started `mongod`). You can access this by pointing your browser to <http://localhost:28017/>. To get the most out of it, you'll want to add `rest=true` to your config and restart the `mongod` process. The web interface gives you a lot of insight into the current state of your server.

### Profiler ###
You can enable the MongoDB profiler by executing:

	db.setProfilingLevel(2);

With it enabled, we can run a command:

	db.unicorns.find({weight: {$gt: 600}});

And then examine the profiler:

	db.system.profile.find()

The output tells us what was run and when, how many documents were scanned, and how much data was returned.

You can disable the profiler by calling `setProfileLevel` again but changing the argument to `0`. Another option is to specify `1` which will only profile queries that take more than 100 milliseconds. Or, you can specify the minimum time, in milliseconds, with a second parameter:

	//profile anything that takes more than 1 second
	db.setProfilingLevel(1, 1000);

### Backups and Restore ###
Within the MongoDB `bin` folder is a `mongodump` executable. Simply executing `mongodump` will connect to localhost and backup all of your databases to a `dump` subfolder. You can type `mongodump --help` to see additional options. Common options are `--db DBNAME` to back up a specific database and `--collection COLLECTIONAME` to back up a specific collection. You can then use the `mongorestore` executable, located in the same `bin` folder, to restore a previously made backup. Again, the `--db` and `--collection` can be specified to restore a specific database and/or collection. 

For example, to back up our `learn` collection to a `backup` folder, we'd execute (this is its own executable which you run in a command/terminal window, not within the mongo shell itself):

	mongodump --db learn --out backup

To restore only the `unicorns` collection, we could then do:

	mongorestore --collection unicorns backup/learn/unicorns.bson

It's worth pointing out that `mongoexport` and `mongoimport` are two other executables which can be used to export and import data from JSON or CSV. For example, we can get a JSON output by doing:

	mongoexport --db learn -collection unicorns

And a CSV output by doing:

	mongoexport --db learn -collection unicorns --csv -fields name,weight,vampires

Note that `mongoexport` and `mongoimport` cannot always represent your data. Only `mongodump` and `mongorestore` should ever be used for actual backups.

### In This Chapter ###
In this chapter we looked a various commands, tools and performance details of using MongoDB. We haven't touched on everything, but we've looked at the most common ones. Indexing in MongoDB is similar to indexing with relational databases, as are many of the tools. However, with MongoDB, many of these are to the point and simple to use.

\clearpage

## Conclusion ##
You should have enough information to start using MongoDB in a real project. There's more to MongoDB than what we've covered, but your next priority should be putting together what we've learned, and getting familiar with the driver you'll be using. The [MongoDB website](http://www.mongodb.com/) has a lot of useful information. The official [MongoDB user group](http://groups.google.com/group/mongodb-user) is a great place to ask questions.

NoSQL was born not only out of necessity, but also out of an interest to try new approaches. It is an acknowledgement that our field is ever advancing and that if we don't try, and sometimes fail, we can never succeed. This, I think, is a good way to lead our professional lives.
